# Semantic Kernel ‚Üí AutoGen Migration Guide

üîÑ **Strategic migration from Microsoft's plugin-based framework to conversation-driven multi-agent architecture**

Migrate from Semantic Kernel's structured plugin approach to AutoGen's flexible multi-agent conversation model. This guide addresses Microsoft's 2025 framework consolidation and helps enterprises transition to the new Agent Framework paradigm.

[![Migration Type](https://img.shields.io/badge/Type-Enterprise%20Framework-blue.svg)](https://www.agentically.sh/ai-agentic-frameworks/migrate/semantic-kernel-to-autogen/)
[![Complexity](https://img.shields.io/badge/Complexity-Medium--High-orange.svg)](https://www.agentically.sh/ai-agentic-frameworks/migration-complexity/)
[![Success Rate](https://img.shields.io/badge/Success%20Rate-89%25-green.svg)](https://www.agentically.sh/ai-agentic-frameworks/migration-success/)
[![Time Required](https://img.shields.io/badge/Time-6--12%20hours-red.svg)](https://www.agentically.sh/ai-agentic-frameworks/migration-calculator/)

## üéØ Why Migrate from Semantic Kernel to AutoGen?

### Microsoft's 2025 Strategic Direction
Microsoft announced that both AutoGen and Semantic Kernel will transition to **maintenance mode**, with the new **Microsoft Agent Framework** becoming the unified solution. However, AutoGen's conversation-based architecture aligns more closely with the new framework direction.

### Current Limitations in Semantic Kernel
- **Plugin Complexity**: Plugin architecture can become unwieldy for complex workflows
- **Limited Multi-Agent Support**: Primarily designed for single-agent scenarios
- **Conversation Limitations**: Less natural conversation flow compared to AutoGen
- **Migration Path**: AutoGen provides clearer migration to Microsoft Agent Framework
- **Enterprise Overhead**: Heavy enterprise features may be unnecessary for many use cases

### AutoGen Advantages
- **Multi-Agent Native**: Designed from ground up for multi-agent conversations
- **Flexible Architecture**: Actor-based model with cross-language support
- **Natural Conversations**: Human-like conversation patterns between agents
- **Microsoft Backed**: Direct path to Microsoft Agent Framework migration
- **Research Focus**: Better suited for experimental and research workflows
- **Simplified Deployment**: Less enterprise overhead for development teams

## üìä Migration Impact Analysis

| Aspect | Semantic Kernel | AutoGen | Improvement |
|--------|----------------|---------|-------------|
| **Multi-Agent Support** | Plugin-based | Native conversations | +400% agent coordination |
| **Development Complexity** | High (enterprise) | Moderate | -30% development time |
| **Conversation Flow** | Structured | Natural | +200% conversation flexibility |
| **Debugging** | Plugin debugging | Conversation tracing | +150% debugging clarity |
| **Extensibility** | Plugin system | Agent roles | +100% customization options |
| **Microsoft Integration** | .NET focused | Python + .NET | +50% language flexibility |
| **Future Compatibility** | Maintenance mode | Active development | +300% long-term viability |

## üó∫Ô∏è Architecture Mapping Reference

### Core Concept Mapping

| Semantic Kernel Concept | AutoGen Equivalent | Migration Notes |
|-------------------------|-------------------|-----------------|
| **Kernel** | `GroupChat` or `Agent Manager` | Central orchestration becomes conversation management |
| **Plugin** | `Agent` with specific role | Each plugin becomes a specialized agent |
| **Function** | `Tool` or Agent method | Functions become agent capabilities |
| **Planner** | `Conversation Flow` | Planning becomes conversational coordination |
| **Memory** | `Conversation History` | Memory becomes conversation context |
| **Connector** | `LLM Configuration` | Direct mapping of LLM connections |
| **Template** | `System Message` | Prompts become agent system messages |

### Architectural Pattern Transformation

| Semantic Kernel Pattern | AutoGen Implementation | Example |
|-------------------------|----------------------|---------|
| **Single Agent + Plugins** | `UserProxyAgent` + `AssistantAgent` | Basic chat with tools |
| **Sequential Planning** | `Sequential Agent Conversation` | Step-by-step agent interactions |
| **Parallel Execution** | `Group Chat` with multiple agents | Concurrent agent discussions |
| **Function Calling** | `Tool-enabled Agents` | Agents with specific capabilities |
| **Memory Management** | `Conversation Memory` | Context preservation across turns |

## üõ†Ô∏è Step-by-Step Migration Process

### Phase 1: Architecture Analysis (1-2 hours)

#### 1.1 Analyze Current Semantic Kernel Structure
```python
# Use our analyzer to assess your current SK implementation
from tools.semantic_kernel_analyzer import SemanticKernelAnalyzer

analyzer = SemanticKernelAnalyzer()
analysis = analyzer.analyze_kernel_app("path/to/your/sk/app")

print(f"Plugins found: {len(analysis.plugins)}")
print(f"Functions identified: {len(analysis.functions)}")
print(f"Migration complexity: {analysis.complexity_score}")
print(f"Recommended agents: {analysis.recommended_agents}")
```

#### 1.2 Design Agent Architecture
```python
# Map your plugins to agent roles
agent_design = {
    "UserProxy": {
        "role": "Human representative",
        "purpose": "Interface with users and coordinate tasks",
        "tools": []
    },
    "DataAnalyst": {
        "role": "Data analysis specialist", 
        "purpose": "Handle data processing and analysis tasks",
        "tools": ["pandas", "sql_query", "visualization"]
    },
    "Researcher": {
        "role": "Information researcher",
        "purpose": "Gather and synthesize information",
        "tools": ["web_search", "document_retrieval"]
    }
}

# Each SK plugin becomes an agent or agent capability
```

### Phase 2: Environment Setup (30 minutes)

#### 2.1 Install AutoGen
```bash
# Install AutoGen (new architecture)
pip install autogen-agentchat[anthropic,openai]
pip install autogen-ext[web-surfer]

# Optional: Install studio for visual debugging
pip install autogen-studio
```

#### 2.2 Environment Configuration
```python
# config.py - Migration-compatible configuration
import os
from autogen import config_list_from_json, config_list_from_models

# LLM Configuration (compatible with SK connectors)
config_list = [
    {
        "model": "gpt-4",  # Same as SK OpenAI connector
        "api_key": os.getenv("OPENAI_API_KEY"),
        "api_type": "openai",
        "base_url": "https://api.openai.com/v1",
        "api_version": None
    },
    {
        "model": "gpt-3.5-turbo",  # Fallback model
        "api_key": os.getenv("OPENAI_API_KEY"), 
        "api_type": "openai"
    }
]

# Azure OpenAI configuration (if migrating from SK Azure)
azure_config = [
    {
        "model": "gpt-4",
        "api_key": os.getenv("AZURE_OPENAI_API_KEY"),
        "api_type": "azure",
        "base_url": f"https://{os.getenv('AZURE_OPENAI_ENDPOINT')}.openai.azure.com/",
        "api_version": "2024-02-01"
    }
]

# Default configuration
llm_config = {
    "config_list": config_list,
    "temperature": 0.7,
    "timeout": 300,
    "seed": 42  # For reproducible results
}
```

### Phase 3: Plugin-to-Agent Migration (3-6 hours)

#### 3.1 Basic Kernel to Agent Conversion

**Semantic Kernel Code:**
```csharp
// Original SK C# code
var kernel = Kernel.CreateBuilder()
    .AddOpenAIChatCompletion("gpt-4", apiKey)
    .Build();

var plugin = kernel.ImportPluginFromType<MathPlugin>();
var result = await kernel.InvokeAsync(plugin["Add"], new() {
    {"number1", "5"},
    {"number2", "3"}
});
```

**AutoGen Equivalent:**
```python
import autogen
from autogen import AssistantAgent, UserProxyAgent

# Create agents (replaces kernel + plugin)
math_assistant = AssistantAgent(
    name="MathAssistant",
    system_message="""You are a mathematics expert. 
    You can perform calculations and explain mathematical concepts.
    Use the provided tools for computations.""",
    llm_config=llm_config,
    tools=[math_add_tool, math_subtract_tool]  # Migrated SK functions
)

user_proxy = UserProxyAgent(
    name="UserProxy",
    human_input_mode="NEVER",
    max_consecutive_auto_reply=10,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
    code_execution_config={"work_dir": "workspace"}
)

# Execute conversation (replaces kernel invoke)
result = user_proxy.initiate_chat(
    math_assistant,
    message="Add 5 and 3, then explain the result"
)
```

#### 3.2 Complex Plugin Migration

**Semantic Kernel Multi-Plugin Example:**
```csharp
// SK multi-plugin orchestration
var kernel = Kernel.CreateBuilder()
    .AddOpenAIChatCompletion("gpt-4", apiKey)
    .Build();

var dataPlugin = kernel.ImportPluginFromType<DataPlugin>();
var analysisPlugin = kernel.ImportPluginFromType<AnalysisPlugin>();
var reportPlugin = kernel.ImportPluginFromType<ReportPlugin>();

// Sequential execution
var data = await kernel.InvokeAsync(dataPlugin["LoadData"], args);
var analysis = await kernel.InvokeAsync(analysisPlugin["Analyze"], data);
var report = await kernel.InvokeAsync(reportPlugin["Generate"], analysis);
```

**AutoGen Multi-Agent Equivalent:**
```python
from autogen import GroupChat, GroupChatManager

# Create specialized agents (one per plugin)
data_agent = AssistantAgent(
    name="DataSpecialist",
    system_message="""You are a data loading and processing expert.
    Load data from various sources and prepare it for analysis.""",
    llm_config=llm_config,
    tools=[load_csv_tool, load_api_tool, clean_data_tool]
)

analysis_agent = AssistantAgent(
    name="DataAnalyst", 
    system_message="""You are a data analysis expert.
    Analyze data and extract meaningful insights.""",
    llm_config=llm_config,
    tools=[statistical_analysis_tool, correlation_tool, visualization_tool]
)

report_agent = AssistantAgent(
    name="ReportWriter",
    system_message="""You are a report generation expert.
    Create comprehensive reports from analysis results.""",
    llm_config=llm_config,
    tools=[generate_chart_tool, format_report_tool, export_pdf_tool]
)

user_proxy = UserProxyAgent(
    name="UserProxy",
    human_input_mode="TERMINATE",
    max_consecutive_auto_reply=1,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE")
)

# Create group chat (replaces sequential kernel calls)
groupchat = GroupChat(
    agents=[user_proxy, data_agent, analysis_agent, report_agent],
    messages=[],
    max_round=20,
    speaker_selection_method="auto"  # Smart agent selection
)

manager = GroupChatManager(groupchat=groupchat, llm_config=llm_config)

# Execute workflow (replaces kernel orchestration)
result = user_proxy.initiate_chat(
    manager,
    message="Load sales data, analyze trends, and generate a comprehensive report"
)
```

#### 3.3 Function/Tool Migration

**Semantic Kernel Function:**
```csharp
public class MathPlugin
{
    [KernelFunction("add")]
    [Description("Add two numbers")]
    public double Add(
        [Description("First number")] double number1,
        [Description("Second number")] double number2)
    {
        return number1 + number2;
    }
}
```

**AutoGen Tool Equivalent:**
```python
from typing import Annotated
import json

def math_add_tool(
    number1: Annotated[float, "First number to add"],
    number2: Annotated[float, "Second number to add"]
) -> str:
    """Add two numbers and return the result."""
    result = number1 + number2
    return json.dumps({
        "operation": "addition",
        "operands": [number1, number2],
        "result": result
    })

# Register tool with agent
math_assistant = AssistantAgent(
    name="MathAssistant",
    system_message="You are a mathematics expert.",
    llm_config=llm_config,
    tools=[math_add_tool]
)
```

#### 3.4 Memory and Context Migration

**Semantic Kernel Memory:**
```csharp
// SK memory management
var memory = new SemanticTextMemory(memoryStore, embeddings);
await memory.SaveInformationAsync("facts", "Paris is the capital of France", "geography");

var recall = await memory.SearchAsync("facts", "What is the capital of France?");
```

**AutoGen Context Management:**
```python
from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent
from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent

# Create retrieval-enabled agents (replaces SK memory)
retrieve_assistant = RetrieveAssistantAgent(
    name="Assistant",
    system_message="You are a helpful assistant with access to retrieved information.",
    llm_config=llm_config,
    description="Assistant with retrieval capabilities"
)

retrieve_user_proxy = RetrieveUserProxyAgent(
    name="UserProxy",
    retrieve_config={
        "task": "qa",
        "docs_path": "knowledge_base/",  # Your migrated knowledge
        "chunk_token_size": 1000,
        "model": "gpt-4",
        "embedding_model": "text-embedding-ada-002",
        "get_or_create": True
    }
)

# Use conversation for memory-enhanced interactions
result = retrieve_user_proxy.initiate_chat(
    retrieve_assistant,
    message="What is the capital of France?",
    problem="Retrieve geographical information"
)
```

### Phase 4: Advanced Patterns (2-4 hours)

#### 4.1 Planning to Conversation Flow

**Semantic Kernel Planner:**
```csharp
// SK sequential planner
var planner = new SequentialPlanner(kernel);
var plan = await planner.CreatePlanAsync("Analyze customer data and generate insights");
var result = await plan.InvokeAsync(kernel);
```

**AutoGen Conversation Planning:**
```python
from autogen import Agent

class PlannerAgent(AssistantAgent):
    """Agent that plans and coordinates other agents"""
    
    def __init__(self, **kwargs):
        super().__init__(
            name="Planner",
            system_message="""You are a task planning expert.
            Break down complex tasks into steps and coordinate other agents.
            
            Available agents:
            - DataAnalyst: Handles data processing and analysis
            - Researcher: Gathers information and insights  
            - ReportWriter: Creates reports and summaries
            
            Plan the workflow and delegate to appropriate agents.""",
            **kwargs
        )

# Create planning workflow
planner = PlannerAgent(llm_config=llm_config)
data_analyst = AssistantAgent(name="DataAnalyst", llm_config=llm_config)
researcher = AssistantAgent(name="Researcher", llm_config=llm_config)
report_writer = AssistantAgent(name="ReportWriter", llm_config=llm_config)

# Planning conversation
groupchat = GroupChat(
    agents=[user_proxy, planner, data_analyst, researcher, report_writer],
    messages=[],
    max_round=30,
    speaker_selection_method="round_robin"
)

manager = GroupChatManager(groupchat=groupchat, llm_config=llm_config)

# Execute planned workflow
result = user_proxy.initiate_chat(
    manager,
    message="Analyze customer data and generate insights"
)
```

#### 4.2 Error Handling and Resilience

```python
from autogen.agentchat.contrib.capabilities.teachability import Teachability

class ResilientAgent(AssistantAgent):
    """Agent with enhanced error handling and learning"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
        # Add teachability (learning from mistakes)
        teachability = Teachability(
            verbosity=0,
            reset_db=False,
            path_to_db_dir="./teachability_db",
            recall_threshold=1.5
        )
        teachability.add_to_agent(self)
    
    async def generate_reply(self, messages, sender, **kwargs):
        """Enhanced reply generation with error handling"""
        try:
            return await super().generate_reply(messages, sender, **kwargs)
        except Exception as e:
            error_msg = f"I encountered an error: {str(e)}. Let me try a different approach."
            return {"content": error_msg, "role": "assistant"}

# Use resilient agents
resilient_assistant = ResilientAgent(
    name="ResilientAssistant",
    system_message="You are a helpful assistant that learns from mistakes.",
    llm_config=llm_config
)
```

### Phase 5: Testing and Validation (1-2 hours)

#### 5.1 Conversation Testing
```python
import unittest
from autogen.test_utils import check_chat_completion

class TestMigration(unittest.TestCase):
    """Test migrated AutoGen functionality"""
    
    def setUp(self):
        """Set up test agents"""
        self.math_assistant = AssistantAgent(
            name="MathAssistant",
            system_message="You are a math expert.",
            llm_config=llm_config,
            tools=[math_add_tool]
        )
        
        self.user_proxy = UserProxyAgent(
            name="UserProxy",
            human_input_mode="NEVER",
            max_consecutive_auto_reply=1
        )
    
    def test_basic_math_conversation(self):
        """Test basic math functionality (migrated from SK)"""
        result = self.user_proxy.initiate_chat(
            self.math_assistant,
            message="Add 5 and 3"
        )
        
        # Verify conversation completed
        self.assertTrue(len(result.chat_history) > 0)
        
        # Check for expected result
        final_message = result.chat_history[-1]["content"]
        self.assertIn("8", final_message)
    
    def test_multi_agent_workflow(self):
        """Test complex workflow (migrated from SK multi-plugin)"""
        
        # Create workflow agents
        groupchat = GroupChat(
            agents=[self.user_proxy, self.math_assistant],
            messages=[],
            max_round=10
        )
        
        manager = GroupChatManager(groupchat=groupchat, llm_config=llm_config)
        
        result = self.user_proxy.initiate_chat(
            manager,
            message="Calculate 5+3, then multiply by 2"
        )
        
        # Verify workflow completion
        self.assertTrue(len(result.chat_history) > 2)
    
    def test_tool_functionality(self):
        """Test that migrated tools work correctly"""
        result = math_add_tool(5.0, 3.0)
        self.assertIn("8", result)

if __name__ == "__main__":
    unittest.main()
```

#### 5.2 Performance Comparison
```python
import time
import psutil
import os

def benchmark_migration():
    """Compare performance between SK and AutoGen implementations"""
    
    test_scenarios = [
        "Perform basic calculation",
        "Analyze simple data set", 
        "Generate summary report"
    ]
    
    print("AutoGen Performance Benchmark")
    print("=" * 40)
    
    for scenario in test_scenarios:
        start_time = time.time()
        start_memory = psutil.Process(os.getpid()).memory_info().rss
        
        # Run AutoGen conversation
        result = user_proxy.initiate_chat(
            math_assistant,
            message=scenario
        )
        
        end_time = time.time()
        end_memory = psutil.Process(os.getpid()).memory_info().rss
        
        print(f"\nScenario: {scenario}")
        print(f"Time: {end_time - start_time:.2f}s")
        print(f"Memory: {(end_memory - start_memory) / 1024 / 1024:.2f}MB")
        print(f"Conversation length: {len(result.chat_history)} turns")

benchmark_migration()
```

## üöÄ Production Deployment

### Docker Configuration
```dockerfile
# Dockerfile for AutoGen deployment
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY requirements.txt .
RUN pip install -r requirements.txt

# Copy application code
COPY . .

# Set environment variables
ENV PYTHONPATH=/app
ENV AUTOGEN_USE_DOCKER=False

# Expose port
EXPOSE 8000

# Run application
CMD ["python", "main.py"]
```

### FastAPI Integration
```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import asyncio

app = FastAPI(title="Migrated AutoGen Service")

class ConversationRequest(BaseModel):
    message: str
    agent_type: str = "general"
    max_rounds: int = 10

class ConversationResponse(BaseModel):
    result: str
    conversation_history: list
    duration: float

@app.post("/chat", response_model=ConversationResponse)
async def start_conversation(request: ConversationRequest):
    """Start a conversation with migrated agents"""
    
    try:
        start_time = time.time()
        
        # Create agents based on request
        assistant = create_agent_by_type(request.agent_type)
        user_proxy = UserProxyAgent(
            name="APIUser",
            human_input_mode="NEVER",
            max_consecutive_auto_reply=request.max_rounds
        )
        
        # Run conversation
        result = user_proxy.initiate_chat(
            assistant,
            message=request.message
        )
        
        duration = time.time() - start_time
        
        return ConversationResponse(
            result=result.summary,
            conversation_history=result.chat_history,
            duration=duration
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    return {"status": "healthy", "framework": "AutoGen"}

def create_agent_by_type(agent_type: str) -> AssistantAgent:
    """Factory function for different agent types"""
    
    agent_configs = {
        "general": {
            "name": "GeneralAssistant",
            "system_message": "You are a helpful general purpose assistant."
        },
        "math": {
            "name": "MathAssistant", 
            "system_message": "You are a mathematics expert.",
            "tools": [math_add_tool, math_subtract_tool]
        },
        "data": {
            "name": "DataAnalyst",
            "system_message": "You are a data analysis expert.",
            "tools": [data_analysis_tools]
        }
    }
    
    config = agent_configs.get(agent_type, agent_configs["general"])
    
    return AssistantAgent(
        llm_config=llm_config,
        **config
    )
```

## üìä Cost & Performance Analysis

### Migration Benefits

| Metric | Semantic Kernel | AutoGen | Improvement |
|--------|----------------|---------|-------------|
| **Setup Time** | 2-4 hours | 1-2 hours | 50% faster |
| **Multi-Agent Support** | Plugin coordination | Native conversations | 300% improvement |
| **Development Speed** | Enterprise complexity | Streamlined | 40% faster |
| **Debugging** | Plugin stack traces | Conversation logs | 200% clearer |
| **Flexibility** | Structured plugins | Conversational agents | 150% more flexible |
| **Future Support** | Maintenance mode | Active development | Long-term viability |

### Cost Comparison (Monthly)
- **Development Time**: -40% (simpler architecture)
- **Maintenance**: -50% (fewer enterprise dependencies)
- **Hosting**: -30% (lighter resource requirements)
- **Training**: -60% (more intuitive conversation model)

## üîß Migration Tools

### Automated Code Converter
```python
# tools/sk_to_autogen_converter.py
from tools.semantic_kernel_analyzer import SemanticKernelAnalyzer

class SemanticKernelToAutoGenConverter:
    """Convert Semantic Kernel plugins to AutoGen agents"""
    
    def __init__(self):
        self.analyzer = SemanticKernelAnalyzer()
    
    def convert_plugin_to_agent(self, plugin_path: str, output_path: str):
        """Convert SK plugin to AutoGen agent"""
        
        # Analyze plugin
        plugin_analysis = self.analyzer.analyze_plugin(plugin_path)
        
        # Generate AutoGen agent code
        agent_code = self.generate_agent_code(plugin_analysis)
        
        # Save converted code
        with open(output_path, 'w') as f:
            f.write(agent_code)
        
        return plugin_analysis
    
    def generate_agent_code(self, analysis):
        """Generate AutoGen agent from SK plugin analysis"""
        
        template = '''
from autogen import AssistantAgent
from typing import Annotated
import json

class {class_name}(AssistantAgent):
    """Migrated from Semantic Kernel plugin: {plugin_name}"""
    
    def __init__(self, llm_config, **kwargs):
        super().__init__(
            name="{agent_name}",
            system_message="""{system_message}""",
            llm_config=llm_config,
            tools={tools},
            **kwargs
        )

{tool_functions}

# Usage example:
# agent = {class_name}(llm_config=your_llm_config)
'''
        
        return template.format(
            class_name=analysis.suggested_class_name,
            plugin_name=analysis.plugin_name,
            agent_name=analysis.suggested_agent_name,
            system_message=analysis.suggested_system_message,
            tools=analysis.converted_tools,
            tool_functions=analysis.tool_function_code
        )

# Usage
converter = SemanticKernelToAutoGenConverter()
converter.convert_plugin_to_agent("MathPlugin.cs", "math_agent.py")
```

## üéØ Common Migration Patterns

### Pattern 1: Single Plugin ‚Üí Single Agent
```python
# SK Plugin
[KernelFunction("calculate")]
public double Calculate(double x, double y) => x * y;

# AutoGen Agent
def calculate_tool(x: float, y: float) -> str:
    return json.dumps({"result": x * y})

agent = AssistantAgent(
    name="Calculator",
    tools=[calculate_tool],
    llm_config=llm_config
)
```

### Pattern 2: Multi-Plugin Workflow ‚Üí Group Chat
```python
# SK Sequential workflow
var result1 = await kernel.InvokeAsync(plugin1["function1"]);
var result2 = await kernel.InvokeAsync(plugin2["function2"], result1);

# AutoGen Group Chat
groupchat = GroupChat(
    agents=[agent1, agent2, user_proxy],
    max_round=10
)
manager = GroupChatManager(groupchat=groupchat, llm_config=llm_config)
result = user_proxy.initiate_chat(manager, message="Execute workflow")
```

### Pattern 3: Memory ‚Üí Conversation History
```python
# SK Memory
await memory.SaveInformationAsync("key", "value");
var recall = await memory.SearchAsync("key", "query");

# AutoGen Conversation Context
# Memory is automatically maintained in conversation history
# Access via: conversation.chat_history
```

## üêõ Common Issues & Solutions

### Issue 1: Plugin Function Signatures
**Problem**: SK functions have different signature patterns
**Solution**:
```python
# Convert SK function to AutoGen tool
# SK: [KernelFunction] public string Process(string input, int count)
# AutoGen:
def process_tool(
    input_text: Annotated[str, "Input text to process"],
    count: Annotated[int, "Number of iterations"]
) -> str:
    """Process input text with specified count"""
    # Your logic here
    return result
```

### Issue 2: Azure Integration
**Problem**: SK Azure connectors need conversion
**Solution**:
```python
# Azure OpenAI configuration for AutoGen
azure_config = {
    "model": "gpt-4",
    "api_type": "azure",
    "api_key": os.getenv("AZURE_OPENAI_API_KEY"),
    "base_url": f"https://{os.getenv('AZURE_OPENAI_ENDPOINT')}.openai.azure.com/",
    "api_version": "2024-02-01"
}

llm_config = {"config_list": [azure_config]}
```

### Issue 3: Complex Planning
**Problem**: SK planners don't have direct AutoGen equivalent
**Solution**:
```python
# Create planning agent
class WorkflowPlanner(AssistantAgent):
    def __init__(self, **kwargs):
        super().__init__(
            name="Planner",
            system_message="""You coordinate complex workflows.
            Break tasks into steps and delegate to specialized agents.""",
            **kwargs
        )
```

## üìö Additional Resources

### Migration Path
1. [AutoGen Basics](https://www.agentically.sh/ai-agentic-frameworks/autogen/basics/)
2. [Multi-Agent Patterns](https://www.agentically.sh/ai-agentic-frameworks/autogen/multi-agent/)
3. [Microsoft Agent Framework](https://www.agentically.sh/ai-agentic-frameworks/microsoft-agent-framework/)
4. [Production Deployment](https://www.agentically.sh/ai-agentic-frameworks/autogen/production/)

### Community Support
- [Discord #semantic-kernel-migration](https://discord.gg/agentically)
- [Migration Success Stories](https://www.agentically.sh/ai-agentic-frameworks/success-stories/)
- [Expert Consultation](https://www.agentically.sh/ai-agentic-frameworks/consultation/)

### Microsoft Resources
- [Microsoft Agent Framework Roadmap](https://github.com/microsoft/semantic-kernel/discussions/5023)
- [AutoGen to Agent Framework Migration](https://microsoft.github.io/autogen/blog/2024/12/10/AutoGenFramework/)
- [Enterprise Migration Guide](https://www.agentically.sh/ai-agentic-frameworks/enterprise-migration/)

---

**Need help with your enterprise migration?** [Get expert assistance ‚Üí](https://www.agentically.sh/ai-agentic-frameworks/migration-support/)

*Built with ‚ù§Ô∏è by [Agentically](https://www.agentically.sh) | [Compare All Frameworks ‚Üí](https://www.agentically.sh/ai-agentic-frameworks/)*